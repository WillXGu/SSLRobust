# SSLRobust
Multitask learning has been shown to strengthen adversarial robustness. When one output is attacked, others are affected as well because adversarial perturbations must also affect the shared encoder layers. Self-supervised labels are intrinsic: if the output is incorrect, possibly due to the unintended effects of an adversarial attack against a different supervised task, we can use the SSL task's intrinsic labels to create and apply a cleaning perturbation!

This notebook & paper were done as part of a research project for Junfeng Yang's Security & Robustness in ML Systems class at Columbia University, with the novel idea of utilizing self-supervised learning to create cleaning perturbations by Chengzhi Mao. The Jigsaw implementation mentioned in our paper, done by my partner Valentine d'Hauteville, is not included in this repository.  
